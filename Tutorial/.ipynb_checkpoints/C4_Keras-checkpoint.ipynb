{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, optimizers\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Keras Network**\n",
    "\n",
    "### **Step 1. Define Network**\n",
    "\n",
    "Neural networks are defined in Keras as a\n",
    "sequence of layers. The container for these layers is the Sequential class. The first step is to\n",
    "create an instance of the Sequential class. Then you can create your layers and add them in\n",
    "the order that they should be connected. For example, we can do this in two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can also do this in one step by creating an array of layers and passing it to the\n",
    "constructor of the Sequential class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [Dense(2)]\n",
    "model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer in the network must define the number of inputs to expect. The way that this\n",
    "is specified can differ depending on the network type, but for a Multilayer Perceptron model\n",
    "this is specified by the input dim attribute. For example, a small Multilayer Perceptron model\n",
    "with 2 inputs in the visible layer, 5 neurons in the hidden layer and one neuron in the output\n",
    "layer can be defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=2))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of a Sequential model as a pipeline with your raw data fed in at the bottom and\n",
    "predictions that come out at the top. This is a helpful conception in Keras as concerns that were\n",
    "traditionally associated with a layer can also be split out and added as separate layers, clearly\n",
    "showing their role in the transform of data from input to prediction. For example, activation\n",
    "functions that transform a summed signal from each neuron in a layer can be extracted and\n",
    "added to the Sequential as a layer-like object called the Activation class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of activation function is most important for the output layer as it will define the\n",
    "format that predictions will take. For example, below are some common predictive modeling\n",
    "problem types and the structure and standard activation function that you can use in the output\n",
    "layer:\n",
    "\n",
    "- **Regression**: Linear activation function, or *linear*, and the number of neurons matching the number of outputs.\n",
    "\n",
    "- **Binary Classification (2 class)**: Logistic activation function, or *sigmoid*, and one neuron the output layer.\n",
    "\n",
    "- **Multiclass Classification (>2 class)**: Softmax activation function, or *softmax*, and one output neuron per class value, assuming a one hot encoded output pattern.\n",
    "\n",
    "### **Step 2. Define Network**\n",
    "\n",
    "Once we have defined our network, we must compile it. Compilation is an efficiency step. It\n",
    "transforms the simple sequence of layers that we defined into a highly efficient series of matrix\n",
    "transforms in a format intended to be executed on your GPU or CPU, depending on how Keras\n",
    "is configured. Think of compilation as a precompute step for your network. It is always required\n",
    "after defining a model.\n",
    "Compilation requires a number of parameters to be specified, specifically tailored to training\n",
    "your network. Specifically, the optimization algorithm to use to train the network and the loss\n",
    "function used to evaluate the network that is minimized by the optimization algorithm. For\n",
    "example, below is a case of compiling a defined model and specifying the stochastic gradient\n",
    "descent (sgd) optimization algorithm and the mean squared error (mean squared error) loss\n",
    "function, intended for a regression type problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, the optimizer can be created and configured before being provided as an argument\n",
    "to the compilation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = optimizers.SGD(lr=0.1, momentum=0.3)\n",
    "model.compile(optimizer=algorithm, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of predictive modeling problem imposes constraints on the type of loss function\n",
    "that can be used. For example, below are some standard loss functions for different predictive\n",
    "model types:\n",
    "\n",
    "- **Regression**: Mean Squared Error or *mean_squared_error*.\n",
    "\n",
    "- **Binary Classification (2 class)**: Logarithmic Loss, also called cross entropy or *binary_crossentropy*.\n",
    "\n",
    "- **Multiclass Classification (>2 class)**: Multiclass Logarithmic Loss or categorical_crossentropy.\n",
    "\n",
    "The most common optimization algorithm is stochastic gradient descent, but Keras also\n",
    "supports a suite of other state-of-the-art optimization algorithms that work well with little or\n",
    "no configuration. Perhaps the most commonly used optimization algorithms because of their\n",
    "generally better performance are:\n",
    "\n",
    "- Stochastic Gradient Descent, or *sgd*, that requires the tuning of a learning rate and momentum.\n",
    "\n",
    "- Adam, or *adam*, that requires the tuning of learning rate.\n",
    "\n",
    "- RMSprop, or *rmsprop*, that requires the tuning of learning rate.\n",
    "\n",
    "Finally, you can also specify metrics to collect while fitting your model in addition to the\n",
    "loss function. Generally, the most useful additional metric to collect is accuracy for classification\n",
    "problems. The metrics to collect are specified by name in an array. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3. Fit Network**\n",
    "\n",
    "Once the network is compiled, it can be fit, which means adapt the weights on a training dataset.\n",
    "Fitting the network requires the training data to be specified, both a matrix of input patterns, X,\n",
    "and an array of matching output patterns, y. The network is trained using the backpropagation\n",
    "algorithm and optimized according to the optimization algorithm and loss function specified\n",
    "when compiling the model.\n",
    "The backpropagation algorithm requires that the network be trained for a speci\f",
    "ed number\n",
    "of epochs or exposures to the training dataset. Each epoch can be partitioned into groups\n",
    "of input-output pattern pairs called batches. This defines the number of patterns that the\n",
    "network is exposed to before the weights are updated within an epoch. It is also an efficiency\n",
    "optimization, ensuring that not too many input patterns are loaded into memory at a time. A\n",
    "minimal example of fitting a network is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once fit, a history object is returned that provides a summary of the performance of the\n",
    "model during training. This includes both the loss and any additional metrics specified when\n",
    "compiling the model, recorded each epoch. Training can take a long time, from seconds to hours\n",
    "to days depending on the size of the network and the size of the training data.\n",
    "By default, a progress bar is displayed on the command line for each epoch. This may create\n",
    "too much noise for you, or may cause problems for your environment, such as if you are in an\n",
    "interactive notebook or IDE. You can reduce the amount of information displayed to just the\n",
    "loss each epoch by setting the verbose argument to 2. You can turn off all output by setting\n",
    "verbose to 0. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, batch_size=10, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4. Evaluate Network**\n",
    "\n",
    "Once the network is trained, it can be evaluated. The network can be evaluated on the training\n",
    "data, but this will not provide a useful indication of the performance of the network as a\n",
    "predictive model, as it has seen all of this data before. We can evaluate the performance of\n",
    "the network on a separate dataset, unseen during testing. This will provide an estimate of the\n",
    "performance of the network at making predictions for unseen data in the future.\n",
    "The model evaluates the loss across all of the test patterns, as well as any other metrics\n",
    "specified when the model was compiled, like classification accuracy. A list of evaluation metrics\n",
    "is returned. For example, for a model compiled with the accuracy metric, we could evaluate it\n",
    "on a new dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5. Make Predictions**\n",
    "\n",
    "Once we are satisfied with the performance of our fit model, we can use it to make predictions\n",
    "on new data. This is as easy as calling the predict() function on the model with an array of\n",
    "new input patterns. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions will be returned in the format provided by the output layer of the network.\n",
    "In the case of a regression problem, these predictions may be in the format of the problem\n",
    "directly, provided by a linear activation function. For a binary classification problem, the\n",
    "predictions may be an array of probabilities for the first class that can be converted to a 1 or 0\n",
    "by rounding.\n",
    "For a multiclass classification problem, the results may be in the form of an array of\n",
    "probabilities (assuming a one hot encoded output variable) that may need to be converted to a\n",
    "single class output prediction using the argmax() NumPy function. Alternately, for classification\n",
    "problems, we can use the predict classes() function that will automatically convert uncrisp\n",
    "predictions to crisp integer class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Keras Functional Models** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
