{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word Embeddings + CNN = Text Classification\n",
    "\n",
    "The architecture is therefore comprised of three key pieces:\n",
    "\n",
    "- Word Embedding: A distributed representation of words where different words that have a similar meaning (based on their usage) also have a similar representation.\n",
    "\n",
    "- Convolutional Model: A feature extraction model that learns to extract salient features from documents represented using a word embedding.\n",
    "\n",
    "- Fully Connected Model: The interpretation of extracted features in terms of a predictive output.\n",
    "\n",
    "## 2. Use a Single Layer CNN Architecture\n",
    "\n",
    "Despite little tuning of hyperparameters, a simple CNN with one layer of convolution\n",
    "performs remarkably well. Our results add to the well-established evidence that\n",
    "unsupervised pre-training of word vectors is an important ingredient in deep learning\n",
    "for NLP.\n",
    "\n",
    "Kim describes the general approach of using CNN for natural language processingï¼š\n",
    "1. Sentences are mapped to embedding vectors and are available as a matrix input to the model. \n",
    "2. Convolutions are performed across the input word-wise using differently sized kernels, such as 2 or 3 words at a time. \n",
    "3. The resulting feature maps are then processed using a max pooling layer to condense or summarize the extracted features.\n",
    "\n",
    "![An example of a CNN Filter and Polling Architecture for Natural Language\n",
    "Processing. Taken from Convolutional Neural Networks for Sentence Classification.](cnn_nlp.jpg)\n",
    "\n",
    "Usefully, he reports his chosen model configuration, discovered via grid search and used across a suite of 7 text classification tasks, summarized as follows:\n",
    "\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 2, 4, 5.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- Weight regularization (L2): 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adadelta.\n",
    "\n",
    "## 3. Dial in CNN Hyperparameters\n",
    "\n",
    "Unfortunately, a downside to CNN-based models - even simple ones - is that they\n",
    "require practitioners to specify the exact model architecture to be used and to set\n",
    "the accompanying hyperparameters. To the uninitiated, making such decisions can\n",
    "seem like something of a black art because there are many free parameters in the\n",
    "model.\n",
    "\n",
    "Their aim was to provide general configurations that can be used for configuring CNNs on new text classification tasks. They provide a nice depiction of the model architecture and the decision points for configuring the model, reproduced below.\n",
    "\n",
    "![Convolutional Neural Network Architecture for Sentence Classification. Taken\n",
    "from A Sensitivity Analysis of (and Practitioners' Guide to) Convolutional Neural Networks for Sentence Classification.](cnn_nlp_2.png)\n",
    "\n",
    "The study makes a number of useful findings that could be used as a starting point for\n",
    "configuring shallow CNN models for text classification. The general findings were as follows:\n",
    "\n",
    "The choice of pre-trained Word2Vec and GloVe embeddings differ from problem to problem, and both performed better than using one hot encoded word vectors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
